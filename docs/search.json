[
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "Lab 6: Machine Learning",
    "section": "",
    "text": "Lab Set Up\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nGetting Basin Characteristics\n\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\nQuestion 1\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()\n\n\n\n\n\n\n\n\nThe documentation PDF tells us that zero_q_freq is the frequency of days with Q=0 mm/day.\nQuestion 2\n\n#EDA\ncamels |&gt; \n  select(aridity, p_mean, q_mean) |&gt; \n  drop_na() |&gt; \n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n# Create a scatter plot of aridity vs rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  scale_color_viridis_c() +\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n#Log Transformation\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n#Log Transforming the color scale\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  # Apply a log transformation to the color scale\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\n\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\n\n# Generate the split\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n# Create a recipe to preprocess the data\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  # Log transform the predictor variables (aridity and p_mean)\n  step_log(all_predictors()) %&gt;%\n  # Add an interaction term between aridity and p_mean\n  step_interact(terms = ~ aridity:p_mean) |&gt; \n  # Drop any rows with missing values in the pred\n  step_naomit(all_predictors(), all_outcomes())\n\n\nbaked_data &lt;- prep(rec, camels_train) |&gt; \n  bake(new_data = NULL)\n\n#  Base lm sets interaction terms with the * symbol\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\n#Predicting\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\n#Using a workflow\n# Define model\nlm_model &lt;- linear_reg() %&gt;%\n  # define the engine\n  set_engine(\"lm\") %&gt;%\n  # define the mode\n  set_mode(\"regression\")\n\n# Instantiate a workflow ...\nlm_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(lm_model) %&gt;%\n  # Fit the model to the training data\n  fit(data = camels_train) \n\n# Extract the model coefficients from the workflow\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\n\n#Making Predictions\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  61\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n#Using a random forest model\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(rf_model) %&gt;%\n  # Fit the model\n  fit(data = camels_train) \n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.592\n2 rsq     standard       0.736\n3 mae     standard       0.367\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n#Workflowset\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     1\n2 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     1\n3 recipe_rand_fore… Prepro… rmse    0.565  0.0249    10 recipe       rand…     2\n4 recipe_rand_fore… Prepro… rsq     0.769  0.0261    10 recipe       rand…     2\n\n\nQuestion 3\n\n#Creating an xgboost regression model\nset.seed(123)\ncamel_split &lt;- initial_split(camels, prop = 0.8)\ncamel_train &lt;- training(camel_split)\ncamel_test  &lt;- testing(camel_split)\ncamel_folds &lt;- vfold_cv(camel_train, v = 10)\n\ncamel_recipe &lt;- recipe(aridity ~ ., data = camel_train)  |&gt; \n  step_dummy(all_nominal_predictors())  |&gt; \n  step_normalize(all_numeric_predictors()) |&gt; \n  step_impute_mean(all_numeric_predictors())\n\nb_model &lt;- boost_tree() |&gt;\n  set_engine(\"xgboost\") |&gt;\n  set_mode(\"classification\")\n\nb_model &lt;- boost_tree(mode = \"regression\") %&gt;%\n  set_engine(\"xgboost\")\n\n\n#Building a neural network model\nnn_model &lt;- bag_mlp(hidden_units = 5, penalty = 0.01) |&gt; \n  set_engine(\"nnet\") |&gt; \n  set_mode(\"classification\")\n\nnn_model &lt;- bag_mlp(mode = \"regression\") %&gt;%\n  set_engine(\"nnet\", times = 25)\n\n\n#Workflow\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model, nn_model, b_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_bag_mlp    Prepro… rmse    0.545  0.0290    10 recipe       bag_…     1\n2 recipe_bag_mlp    Prepro… rsq     0.790  0.0234    10 recipe       bag_…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2\n5 recipe_rand_fore… Prepro… rmse    0.565  0.0253    10 recipe       rand…     3\n6 recipe_rand_fore… Prepro… rsq     0.769  0.0263    10 recipe       rand…     3\n7 recipe_boost_tree Prepro… rmse    0.600  0.0289    10 recipe       boos…     4\n8 recipe_boost_tree Prepro… rsq     0.745  0.0268    10 recipe       boos…     4\n\n\nLooking at the r squared value for all four models, the neural network model using the bag_mlp function has the highest value. Therefore it is the best model and the one I would choose to move forward with.\nBuild your own!\n\n#Data Splitting\ncamels2 &lt;- camels |&gt;\n  mutate(logQmean = log(q_mean)) |&gt;\n  select(logQmean, p_mean, aridity, soil_depth_pelletier, max_water_content, organic_frac, frac_snow, pet_mean, soil_depth_statsgo, elev_mean, slope_mean, area_gages2) |&gt;\n  na.omit()\n\nset.seed(123)\ncamel_split2 &lt;- initial_split(camels2, prop = 0.75)\ncamel_train2 &lt;- training(camel_split2)\ncamel_test2  &lt;- testing(camel_split2)\ncamel_folds2 &lt;- vfold_cv(camel_train2, v = 10)\n\n\n#Recipe\nrec_camel &lt;-  recipe(logQmean ~ p_mean + pet_mean + elev_mean + area_gages2 + max_water_content + slope_mean, data = camel_train2) %&gt;%\n  step_scale(all_predictors()) |&gt;\n  step_center(all_predictors())\n\nI chose this formula because the chosen variables are the ones that influence stream flow from the downloaded PDF. I feel that the chosen variables will have a statistically significant correlation to stream flow.\n\n#Defining the models\nrf_model_camel &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nxgb_camel &lt;- boost_tree(mode = \"regression\") %&gt;%\n  set_engine(\"xgboost\")\n\ndt_camel &lt;- decision_tree(mode = \"regression\") |&gt;\n  set_engine(\"rpart\")\n\n\n#Workflow Set\nwf_2 &lt;- workflow_set(list(rec_camel), list(xgb_camel, dt_camel, rf_model_camel)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\n→ A | error:   [10:54:25] src/data/data.cc:461: Check failed: valid: Label contains NaN, infinity or a value too large.\n               Stack trace:\n                 [bt] (0) 1   xgboost.so                          0x0000000133809c7c dmlc::LogMessageFatal::~LogMessageFatal() + 124\n                 [bt] (1) 2   xgboost.so                          0x00000001338a1460 xgboost::MetaInfo::SetInfoFromHost(xgboost::GenericParameter const&, xgboost::StringView, xgboost::Json) + 3616\n                 [bt] (2) 3   xgboost.so                          0x00000001338a26e8 xgboost::MetaInfo::SetInfo(xgboost::GenericParameter const&, char const*, void const*, xgboost::DataType, unsigned long) + 168\n                 [bt] (3) 4   xgboost.so                          0x00000001339c0184 XGDMatrixSetFloatInfo + 132\n                 [bt] (4) 5   xgboost.so                          0x0000000133804eec XGDMatrixSetInfo_R + 620\n                 [bt] (5) 6   libR.dylib                          0x00000001033f89b4 R_doDotCall + 1588\n                 [bt] (6) 7   libR.dylib                          0x0000000103454cfc bcEval_loop + 128060\n                 [bt] (7) \n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x2\n\n\nThere were issues with some computations   A: x9\n\n\n\n\n\n→ A | error:   Error: Missing data in dependent variable.\n\nautoplot(wf_2)\n\n\n\n\n\n\n\n\nThe random forest model is the best fit for the CAMEL data set. We can come to this conclusion by looking at the r squared values on the autoplot and can see that the random forest model has the highest one, meaning it will do the best job for this data set.\n\n#Extract and Evaluate\nrf_wf_camel &lt;- workflow() %&gt;%\n  add_recipe(rec_camel) %&gt;%\n  add_model(rf_model_camel) %&gt;%\n  fit(data = camel_train2) \n\nrf_data2 &lt;- augment(rf_wf_camel, new_data = camel_test2)\ndim(rf_data2)\n\n[1] 168  13\n\nggplot(rf_data2, aes(x = .pred, y = logQmean)) +\n  geom_point(color = \"skyblue\") +\n  geom_abline() +\n  theme_linedraw() +\n  labs(title = \"Observed vs. Predicted LogQmean Values\",\n       x = \"Predicted Values\",\n       y = \"Observed Values\")\n\n\n\n\n\n\n\n\nThe observed and predicted values follow a linear relationship, leading me to determine that there is a correlation between my chosen variables and the log Q mean of the stream flow."
  },
  {
    "objectID": "hyperparameter-tuning.html",
    "href": "hyperparameter-tuning.html",
    "title": "Lab 8: Hyper Parameter Tuning",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\nlibrary(visdat)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(patchwork)\n\nData Cleaning/Import/Tidy/Transform\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\n# download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n    #        'data/camels_attributes_v2.0.pdf')\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\n#walk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels &lt;- purrr::map(local_files, ~read_delim(.x, show_col_types = FALSE))\n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\nsummary(camels)\n\n   gauge_id             p_mean          pet_mean     p_seasonality     \n Length:671         Min.   :0.6446   Min.   :1.899   Min.   :-1.43546  \n Class :character   1st Qu.:2.3731   1st Qu.:2.335   1st Qu.:-0.26352  \n Mode  :character   Median :3.2295   Median :2.688   Median : 0.08093  \n                    Mean   :3.2577   Mean   :2.787   Mean   :-0.04128  \n                    3rd Qu.:3.7835   3rd Qu.:3.146   3rd Qu.: 0.22399  \n                    Max.   :8.9369   Max.   :4.744   Max.   : 0.92202  \n                                                                       \n   frac_snow          aridity       high_prec_freq  high_prec_dur  \n Min.   :0.00000   Min.   :0.2203   Min.   : 7.90   Min.   :1.075  \n 1st Qu.:0.03514   1st Qu.:0.6957   1st Qu.:18.50   1st Qu.:1.209  \n Median :0.09793   Median :0.8551   Median :22.00   Median :1.282  \n Mean   :0.17760   Mean   :1.0565   Mean   :20.93   Mean   :1.350  \n 3rd Qu.:0.22306   3rd Qu.:1.2673   3rd Qu.:24.23   3rd Qu.:1.440  \n Max.   :0.90633   Max.   :5.2079   Max.   :32.70   Max.   :2.091  \n                                                                   \n high_prec_timing   low_prec_freq    low_prec_dur    low_prec_timing   \n Length:671         Min.   :169.9   Min.   : 2.789   Length:671        \n Class :character   1st Qu.:232.7   1st Qu.: 4.241   Class :character  \n Mode  :character   Median :255.8   Median : 4.950   Mode  :character  \n                    Mean   :254.6   Mean   : 5.954                     \n                    3rd Qu.:278.9   3rd Qu.: 6.702                     \n                    Max.   :348.7   Max.   :36.513                     \n                                                                       \n geol_1st_class     glim_1st_class_frac geol_2nd_class     glim_2nd_class_frac\n Length:671         Min.   :0.2967      Length:671         Min.   :0.000000   \n Class :character   1st Qu.:0.6083      Class :character   1st Qu.:0.002894   \n Mode  :character   Median :0.8294      Mode  :character   Median :0.136540   \n                    Mean   :0.7855                         Mean   :0.155426   \n                    3rd Qu.:0.9971                         3rd Qu.:0.266373   \n                    Max.   :1.0000                         Max.   :0.489930   \n                                                                              \n carbonate_rocks_frac geol_porostiy     geol_permeability soil_depth_pelletier\n Min.   :0.00000      Min.   :0.01000   Min.   :-16.50    Min.   : 0.2667     \n 1st Qu.:0.00000      1st Qu.:0.06767   1st Qu.:-14.77    1st Qu.: 1.0000     \n Median :0.00000      Median :0.13190   Median :-13.96    Median : 1.2283     \n Mean   :0.11874      Mean   :0.12637   Mean   :-13.89    Mean   :10.8728     \n 3rd Qu.:0.04333      3rd Qu.:0.18623   3rd Qu.:-13.00    3rd Qu.:12.8894     \n Max.   :1.00000      Max.   :0.28000   Max.   :-10.90    Max.   :50.0000     \n                      NA's   :3                                               \n soil_depth_statsgo soil_porosity    soil_conductivity max_water_content\n Min.   :0.3999     Min.   :0.3733   Min.   : 0.4469   Min.   :0.0866   \n 1st Qu.:1.1054     1st Qu.:0.4309   1st Qu.: 0.9321   1st Qu.:0.4293   \n Median :1.4577     Median :0.4422   Median : 1.3477   Median :0.5579   \n Mean   :1.2932     Mean   :0.4426   Mean   : 1.7405   Mean   :0.5280   \n 3rd Qu.:1.5000     3rd Qu.:0.4554   3rd Qu.: 1.9323   3rd Qu.:0.6450   \n Max.   :1.5000     Max.   :0.6800   Max.   :13.9557   Max.   :1.0520   \n                                                                        \n   sand_frac        silt_frac        clay_frac        water_frac     \n Min.   : 8.184   Min.   : 2.985   Min.   : 1.846   Min.   : 0.0000  \n 1st Qu.:25.437   1st Qu.:23.947   1st Qu.:13.999   1st Qu.: 0.0000  \n Median :35.269   Median :34.059   Median :18.663   Median : 0.0000  \n Mean   :36.468   Mean   :33.859   Mean   :19.886   Mean   : 0.1017  \n 3rd Qu.:44.457   3rd Qu.:43.639   3rd Qu.:25.420   3rd Qu.: 0.0000  \n Max.   :91.976   Max.   :67.775   Max.   :50.354   Max.   :19.3545  \n                                                                     \n  organic_frac       other_frac       gauge_lat       gauge_lon      \n Min.   : 0.0000   Min.   : 0.000   Min.   :27.05   Min.   :-124.39  \n 1st Qu.: 0.0000   1st Qu.: 0.000   1st Qu.:35.70   1st Qu.:-110.41  \n Median : 0.0000   Median : 1.309   Median :39.25   Median : -92.78  \n Mean   : 0.5918   Mean   : 9.825   Mean   :39.24   Mean   : -95.79  \n 3rd Qu.: 0.0000   3rd Qu.:11.737   3rd Qu.:43.21   3rd Qu.: -81.77  \n Max.   :57.8631   Max.   :99.378   Max.   :48.82   Max.   : -67.94  \n                                                                     \n   elev_mean         slope_mean        area_gages2       area_geospa_fabric\n Min.   :  10.21   Min.   :  0.8222   Min.   :    4.03   Min.   :    4.1   \n 1st Qu.: 249.67   1st Qu.:  7.4268   1st Qu.:  122.28   1st Qu.:  128.0   \n Median : 462.72   Median : 28.8016   Median :  329.68   Median :  340.7   \n Mean   : 759.42   Mean   : 46.1953   Mean   :  792.62   Mean   :  808.1   \n 3rd Qu.: 928.88   3rd Qu.: 73.1695   3rd Qu.:  794.29   3rd Qu.:  804.5   \n Max.   :3571.18   Max.   :255.6884   Max.   :25791.04   Max.   :25817.8   \n                                                                           \n  frac_forest        lai_max          lai_diff         gvf_max      \n Min.   :0.0000   Min.   :0.3671   Min.   :0.1544   Min.   :0.1843  \n 1st Qu.:0.2771   1st Qu.:1.8143   1st Qu.:1.1968   1st Qu.:0.6086  \n Median :0.8137   Median :3.3713   Median :2.3365   Median :0.7803  \n Mean   :0.6395   Mean   :3.2160   Mean   :2.4486   Mean   :0.7221  \n 3rd Qu.:0.9724   3rd Qu.:4.6963   3rd Qu.:3.7574   3rd Qu.:0.8649  \n Max.   :1.0000   Max.   :5.5821   Max.   :4.8315   Max.   :0.9157  \n                                                                    \n    gvf_diff      dom_land_cover_frac dom_land_cover     root_depth_50   \n Min.   :0.0290   Min.   :0.3145      Length:671         Min.   :0.1200  \n 1st Qu.:0.1883   1st Qu.:0.6511      Class :character   1st Qu.:0.1654  \n Median :0.3160   Median :0.8582      Mode  :character   Median :0.1800  \n Mean   :0.3227   Mean   :0.8100                         Mean   :0.1788  \n 3rd Qu.:0.4627   3rd Qu.:0.9967                         3rd Qu.:0.1900  \n Max.   :0.6522   Max.   :1.0000                         Max.   :0.2500  \n                                                         NA's   :24      \n root_depth_99       q_mean          runoff_ratio        slope_fdc     \n Min.   :1.500   Min.   :0.004553   Min.   :0.004238   Min.   :0.0000  \n 1st Qu.:1.522   1st Qu.:0.632918   1st Qu.:0.242443   1st Qu.:0.8978  \n Median :1.800   Median :1.131818   Median :0.350664   Median :1.2829  \n Mean   :1.830   Mean   :1.493967   Mean   :0.387146   Mean   :1.2372  \n 3rd Qu.:2.000   3rd Qu.:1.750901   3rd Qu.:0.506681   3rd Qu.:1.6306  \n Max.   :3.100   Max.   :9.688438   Max.   :1.362132   Max.   :2.4973  \n NA's   :24      NA's   :1          NA's   :1          NA's   :1       \n baseflow_index      stream_elas            q5                q95        \n Min.   :0.006858   Min.   :-0.6363   Min.   :0.000000   Min.   : 0.000  \n 1st Qu.:0.397430   1st Qu.: 1.3177   1st Qu.:0.009155   1st Qu.: 2.066  \n Median :0.504923   Median : 1.7006   Median :0.081568   Median : 3.769  \n Mean   :0.491447   Mean   : 1.8322   Mean   :0.171803   Mean   : 5.057  \n 3rd Qu.:0.600345   3rd Qu.: 2.2255   3rd Qu.:0.219522   3rd Qu.: 6.288  \n Max.   :0.977556   Max.   : 6.2405   Max.   :2.424938   Max.   :31.817  \n                    NA's   :1         NA's   :1          NA's   :1       \n  high_q_freq        high_q_dur       low_q_freq       low_q_dur     \n Min.   :  0.000   Min.   : 0.000   Min.   :  0.00   Min.   :  0.00  \n 1st Qu.:  6.412   1st Qu.: 1.821   1st Qu.: 37.44   1st Qu.: 10.00  \n Median : 15.100   Median : 2.848   Median : 96.00   Median : 15.52  \n Mean   : 25.745   Mean   : 6.913   Mean   :107.62   Mean   : 22.28  \n 3rd Qu.: 35.788   3rd Qu.: 7.554   3rd Qu.:162.14   3rd Qu.: 26.91  \n Max.   :172.800   Max.   :92.559   Max.   :356.80   Max.   :209.88  \n NA's   :1         NA's   :1        NA's   :1        NA's   :1       \n  zero_q_freq         hfd_mean    \n Min.   :0.00000   Min.   :112.2  \n 1st Qu.:0.00000   1st Qu.:160.2  \n Median :0.00000   Median :173.8  \n Mean   :0.03415   Mean   :182.5  \n 3rd Qu.:0.00000   3rd Qu.:204.1  \n Max.   :0.96537   Max.   :287.8  \n NA's   :1         NA's   :1      \n\nskimr::skim(camels)\n\n\nData summary\n\n\nName\ncamels\n\n\nNumber of rows\n671\n\n\nNumber of columns\n58\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n52\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ngauge_id\n0\n1.00\n8\n8\n0\n671\n0\n\n\nhigh_prec_timing\n0\n1.00\n3\n3\n0\n4\n0\n\n\nlow_prec_timing\n0\n1.00\n3\n3\n0\n4\n0\n\n\ngeol_1st_class\n0\n1.00\n12\n31\n0\n12\n0\n\n\ngeol_2nd_class\n138\n0.79\n12\n31\n0\n13\n0\n\n\ndom_land_cover\n0\n1.00\n12\n38\n0\n12\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\np_mean\n0\n1.00\n3.26\n1.41\n0.64\n2.37\n3.23\n3.78\n8.94\n▃▇▂▁▁\n\n\npet_mean\n0\n1.00\n2.79\n0.55\n1.90\n2.34\n2.69\n3.15\n4.74\n▇▇▅▂▁\n\n\np_seasonality\n0\n1.00\n-0.04\n0.53\n-1.44\n-0.26\n0.08\n0.22\n0.92\n▁▂▃▇▂\n\n\nfrac_snow\n0\n1.00\n0.18\n0.20\n0.00\n0.04\n0.10\n0.22\n0.91\n▇▂▁▁▁\n\n\naridity\n0\n1.00\n1.06\n0.62\n0.22\n0.70\n0.86\n1.27\n5.21\n▇▂▁▁▁\n\n\nhigh_prec_freq\n0\n1.00\n20.93\n4.55\n7.90\n18.50\n22.00\n24.23\n32.70\n▂▃▇▇▁\n\n\nhigh_prec_dur\n0\n1.00\n1.35\n0.19\n1.08\n1.21\n1.28\n1.44\n2.09\n▇▅▂▁▁\n\n\nlow_prec_freq\n0\n1.00\n254.65\n35.12\n169.90\n232.70\n255.85\n278.92\n348.70\n▂▅▇▅▁\n\n\nlow_prec_dur\n0\n1.00\n5.95\n3.20\n2.79\n4.24\n4.95\n6.70\n36.51\n▇▁▁▁▁\n\n\nglim_1st_class_frac\n0\n1.00\n0.79\n0.20\n0.30\n0.61\n0.83\n1.00\n1.00\n▁▃▃▃▇\n\n\nglim_2nd_class_frac\n0\n1.00\n0.16\n0.14\n0.00\n0.00\n0.14\n0.27\n0.49\n▇▃▃▂▁\n\n\ncarbonate_rocks_frac\n0\n1.00\n0.12\n0.26\n0.00\n0.00\n0.00\n0.04\n1.00\n▇▁▁▁▁\n\n\ngeol_porostiy\n3\n1.00\n0.13\n0.07\n0.01\n0.07\n0.13\n0.19\n0.28\n▇▆▇▇▂\n\n\ngeol_permeability\n0\n1.00\n-13.89\n1.18\n-16.50\n-14.77\n-13.96\n-13.00\n-10.90\n▂▅▇▅▂\n\n\nsoil_depth_pelletier\n0\n1.00\n10.87\n16.24\n0.27\n1.00\n1.23\n12.89\n50.00\n▇▁▁▁▁\n\n\nsoil_depth_statsgo\n0\n1.00\n1.29\n0.27\n0.40\n1.11\n1.46\n1.50\n1.50\n▁▁▂▂▇\n\n\nsoil_porosity\n0\n1.00\n0.44\n0.02\n0.37\n0.43\n0.44\n0.46\n0.68\n▃▇▁▁▁\n\n\nsoil_conductivity\n0\n1.00\n1.74\n1.52\n0.45\n0.93\n1.35\n1.93\n13.96\n▇▁▁▁▁\n\n\nmax_water_content\n0\n1.00\n0.53\n0.15\n0.09\n0.43\n0.56\n0.64\n1.05\n▁▅▇▃▁\n\n\nsand_frac\n0\n1.00\n36.47\n15.63\n8.18\n25.44\n35.27\n44.46\n91.98\n▅▇▅▁▁\n\n\nsilt_frac\n0\n1.00\n33.86\n13.25\n2.99\n23.95\n34.06\n43.64\n67.77\n▂▆▇▆▁\n\n\nclay_frac\n0\n1.00\n19.89\n9.32\n1.85\n14.00\n18.66\n25.42\n50.35\n▃▇▅▂▁\n\n\nwater_frac\n0\n1.00\n0.10\n0.94\n0.00\n0.00\n0.00\n0.00\n19.35\n▇▁▁▁▁\n\n\norganic_frac\n0\n1.00\n0.59\n3.84\n0.00\n0.00\n0.00\n0.00\n57.86\n▇▁▁▁▁\n\n\nother_frac\n0\n1.00\n9.82\n16.83\n0.00\n0.00\n1.31\n11.74\n99.38\n▇▁▁▁▁\n\n\ngauge_lat\n0\n1.00\n39.24\n5.21\n27.05\n35.70\n39.25\n43.21\n48.82\n▂▃▇▆▅\n\n\ngauge_lon\n0\n1.00\n-95.79\n16.21\n-124.39\n-110.41\n-92.78\n-81.77\n-67.94\n▆▃▇▇▅\n\n\nelev_mean\n0\n1.00\n759.42\n786.00\n10.21\n249.67\n462.72\n928.88\n3571.18\n▇▂▁▁▁\n\n\nslope_mean\n0\n1.00\n46.20\n47.12\n0.82\n7.43\n28.80\n73.17\n255.69\n▇▂▂▁▁\n\n\narea_gages2\n0\n1.00\n792.62\n1701.95\n4.03\n122.28\n329.68\n794.30\n25791.04\n▇▁▁▁▁\n\n\narea_geospa_fabric\n0\n1.00\n808.08\n1709.85\n4.10\n127.98\n340.70\n804.50\n25817.78\n▇▁▁▁▁\n\n\nfrac_forest\n0\n1.00\n0.64\n0.37\n0.00\n0.28\n0.81\n0.97\n1.00\n▃▁▁▂▇\n\n\nlai_max\n0\n1.00\n3.22\n1.52\n0.37\n1.81\n3.37\n4.70\n5.58\n▅▆▃▅▇\n\n\nlai_diff\n0\n1.00\n2.45\n1.33\n0.15\n1.20\n2.34\n3.76\n4.83\n▇▇▇▆▇\n\n\ngvf_max\n0\n1.00\n0.72\n0.17\n0.18\n0.61\n0.78\n0.86\n0.92\n▁▁▂▃▇\n\n\ngvf_diff\n0\n1.00\n0.32\n0.15\n0.03\n0.19\n0.32\n0.46\n0.65\n▃▇▅▇▁\n\n\ndom_land_cover_frac\n0\n1.00\n0.81\n0.18\n0.31\n0.65\n0.86\n1.00\n1.00\n▁▂▃▃▇\n\n\nroot_depth_50\n24\n0.96\n0.18\n0.03\n0.12\n0.17\n0.18\n0.19\n0.25\n▃▃▇▂▂\n\n\nroot_depth_99\n24\n0.96\n1.83\n0.30\n1.50\n1.52\n1.80\n2.00\n3.10\n▇▃▂▁▁\n\n\nq_mean\n1\n1.00\n1.49\n1.54\n0.00\n0.63\n1.13\n1.75\n9.69\n▇▁▁▁▁\n\n\nrunoff_ratio\n1\n1.00\n0.39\n0.23\n0.00\n0.24\n0.35\n0.51\n1.36\n▆▇▂▁▁\n\n\nslope_fdc\n1\n1.00\n1.24\n0.51\n0.00\n0.90\n1.28\n1.63\n2.50\n▂▅▇▇▁\n\n\nbaseflow_index\n0\n1.00\n0.49\n0.16\n0.01\n0.40\n0.50\n0.60\n0.98\n▁▃▇▅▁\n\n\nstream_elas\n1\n1.00\n1.83\n0.78\n-0.64\n1.32\n1.70\n2.23\n6.24\n▁▇▃▁▁\n\n\nq5\n1\n1.00\n0.17\n0.27\n0.00\n0.01\n0.08\n0.22\n2.42\n▇▁▁▁▁\n\n\nq95\n1\n1.00\n5.06\n4.94\n0.00\n2.07\n3.77\n6.29\n31.82\n▇▂▁▁▁\n\n\nhigh_q_freq\n1\n1.00\n25.74\n29.07\n0.00\n6.41\n15.10\n35.79\n172.80\n▇▂▁▁▁\n\n\nhigh_q_dur\n1\n1.00\n6.91\n10.07\n0.00\n1.82\n2.85\n7.55\n92.56\n▇▁▁▁▁\n\n\nlow_q_freq\n1\n1.00\n107.62\n82.24\n0.00\n37.44\n96.00\n162.14\n356.80\n▇▆▅▂▁\n\n\nlow_q_dur\n1\n1.00\n22.28\n21.66\n0.00\n10.00\n15.52\n26.91\n209.88\n▇▁▁▁▁\n\n\nzero_q_freq\n1\n1.00\n0.03\n0.11\n0.00\n0.00\n0.00\n0.00\n0.97\n▇▁▁▁▁\n\n\nhfd_mean\n1\n1.00\n182.52\n33.53\n112.25\n160.16\n173.77\n204.05\n287.75\n▂▇▃▂▁\n\n\n\n\n\nData Splitting\n\nset.seed(123)\n\nsplit_lab8 &lt;- initial_split(camels, prop = 0.8)\ntrain_lab8 &lt;- training(split_lab8)\ntest_lab8  &lt;- testing(split_lab8)\n\nrec8 = recipe(q_mean ~ low_prec_freq + p_mean, data = train_lab8) |&gt;\n # step_rm(gauge_lat, gauge_lon) |&gt;\n  step_unknown(all_nominal_predictors()) |&gt;\n  step_dummy(all_nominal()) |&gt;  \n  step_scale(all_numeric_predictors()) |&gt;  \n  step_center(all_numeric_predictors()) |&gt;\n  step_naomit(all_predictors(), all_outcomes())\n\nfolds8 &lt;- vfold_cv(train_lab8, v = 10)\n\nBuilding Models\n\nrf_model8 &lt;- rand_forest() |&gt; \n  set_engine(\"ranger\") |&gt; \n  set_mode(\"regression\")\n\nlm_model8 &lt;- linear_reg() |&gt; \n  set_engine(\"lm\") |&gt; \n  set_mode(\"regression\")\n\nxgb_model8 &lt;- boost_tree() |&gt; \n  set_engine(\"xgboost\") |&gt; \n  set_mode(\"regression\")\n\nmodels &lt;- list(\n  rf = rf_model8,\n  lm = lm_model8,\n  xgb = xgb_model8\n)\n\nrm(wf8)\n\nWarning in rm(wf8): object 'wf8' not found\n\nwf8 &lt;- workflow_set(list(rec8), list(lm_model8, rf_model8, xgb_model8)) |&gt;\n  workflow_map('fit_resamples', resamples = folds8) \n\nautoplot(wf8)\n\n\n\n\n\n\n\n\nHere we can see the r squared values for all three models. The model with the highest r squared value is the best fit for our data set, so in this case it is the random forest model and that is the one I will move ahead with. Using the regression mode allows us to predict the continuous outcome variable, like q_mean, from our multiple independent variables.\nModel Tuning\n\nrf_tune &lt;- rand_forest(trees = tune(), min_n = tune()) |&gt;\n  set_engine(\"ranger\") |&gt;\n  set_mode(\"regression\")\n\nwf_tune &lt;-  workflow(rec8, rf_tune)\n\nCheck Tunable Values\n\ndials &lt;- extract_parameter_set_dials(wf_tune) \ndials$object\n\n[[1]]\n# Trees (quantitative)\nRange: [1, 2000]\n\n[[2]]\nMinimal Node Size (quantitative)\nRange: [2, 40]\n\n\nDefine the Search Space\n\nmy.grid &lt;- dials |&gt; \n  update(trees = trees(c(50, 500))) |&gt;\n  grid_latin_hypercube(size = 25)\n\nWarning: `grid_latin_hypercube()` was deprecated in dials 1.3.0.\nℹ Please use `grid_space_filling()` instead.\n\nrange(my.grid$trees)\n\n[1]  53 483\n\nplotly::plot_ly(my.grid, \n               x = ~trees, \n               y = ~min_n)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\nTune the Model\n\nmodel_params &lt;-  tune_grid(\n    wf_tune,\n    resamples = folds8,\n    grid = my.grid,\n    metrics = metric_set(rmse, rsq, mae),\n    control = control_grid(save_pred = TRUE)\n  )\n\nautoplot(model_params)\n\n\n\n\n\n\n\n\nCheck the skill of the tuned model\n\ntuned_results &lt;- tune_grid(\n  wf_tune,\n  resamples = folds8,\n  grid = 25\n)\n\nmetrics &lt;- collect_metrics(tuned_results)\n\nshow_best(model_params, metric = \"mae\")\n\n# A tibble: 5 × 8\n  trees min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1   483    11 mae     standard   0.350    10  0.0188 Preprocessor1_Model25\n2   125     8 mae     standard   0.351    10  0.0196 Preprocessor1_Model03\n3   458    14 mae     standard   0.351    10  0.0189 Preprocessor1_Model19\n4   418    16 mae     standard   0.352    10  0.0185 Preprocessor1_Model15\n5    99     9 mae     standard   0.353    10  0.0210 Preprocessor1_Model18\n\nhp_best &lt;- select_best(model_params, metric = \"mae\")\n\nWhen looking at the show_best tibble, the hyper parameter set that is best for this model is 205 for the trees hyper parameter and 15 for min_n. This hyper parameter has the lowest standard error and the highest mean, showing that this set will work best for my data.\nFinalize your model\n\nfinalize &lt;- finalize_workflow(wf_tune, hp_best)\n\nFinal Model Verification\n\nfinal_fit &lt;- last_fit(finalize, split = split_lab8)\n\ncollect_metrics(final_fit)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.498 Preprocessor1_Model1\n2 rsq     standard       0.903 Preprocessor1_Model1\n\n\nThe final model performs better on the test data than it did on the training data. The final model has a root mean squared error of 0.497, which is the average difference between the predicted values from the model and the actual values. This is much lower than the rmse of the training data, which was about 0.55. The final model also has a higher r-squared value than the training data, with a value of 0.903 compared to 0.88 for the training data. The r-squared value of 0.9 means that about 90% of the variance in the dependent variable can be explained by the independent variable.\n\npreds &lt;- collect_predictions(final_fit)\n\n\nggplot(preds, aes(x = q_mean, y = .pred, color = .pred)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkblue\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  scale_color_viridis_c(option = \"C\") +\n  labs(\n    title = \"Q Mean Predicted vs. Actual Values\",\n    x = \"Actual Values\",\n    y = \"Predicted Values\",\n    color = \"Prediction\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nBuilding a Map!\n\nfinal_model_fit &lt;- fit(finalize, data = camels)\npredicted_data &lt;- augment(final_model_fit, new_data = camels) |&gt;\n  mutate(residual = (.pred - q_mean^2))\n\nmap_pred &lt;- ggplot(predicted_data, aes(x = gauge_lon, y = gauge_lat, color = .pred)) +\n  geom_point(size = 1, alpha = 0.8) +\n  coord_fixed() +\n  scale_fill_viridis_c(option = \"C\") +\n  labs(\n    title = \"Predicted Values\",\n    x = \"Longitude\",\n    y = \"Latitude\",\n    fill = \"Prediction\"\n  ) +\n  theme_minimal()\n\nmap_resid &lt;- ggplot(predicted_data, aes(x = gauge_lon, y = gauge_lat, color = residual)) +\n  geom_point(size = 1, alpha = 0.8) +\n  coord_fixed() +\n  scale_fill_viridis_c(option = \"A\") +\n  labs(\n    title = \"Squared Residuals\",\n    x = \"Longitude\",\n    y = \"Latitude\",\n    fill = \"Residual²\"\n  ) +\n  theme_minimal()\n\nmap_pred / map_resid"
  }
]